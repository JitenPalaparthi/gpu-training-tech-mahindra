
# InfiniBand vs RDMA

## â“ Misconception Clarified
**InfiniBand is not faster than RDMA â€” it enables RDMA.**

RDMA (Remote Direct Memory Access) is a **technology**, while InfiniBand is a **transport protocol and hardware platform** that implements RDMA very efficiently.

---

## ğŸ“Œ Definitions

| Term         | What it is             | Relationship              |
|--------------|------------------------|---------------------------|
| **RDMA**     | Technology/mechanism   | Used by InfiniBand (and also RoCE, iWARP) |
| **InfiniBand** | Transport protocol + hardware | Implements RDMA most efficiently |

---

## âœ… Why InfiniBand is Often â€œFasterâ€ in Practice

| Reason | Explanation |
|--------|-------------|
| ğŸš€ **Lower latency** | InfiniBand is optimized for <2Î¼s latency vs 10â€“20Î¼s with RoCEv2 |
| ğŸ›£ï¸ **Lossless fabric** | Built-in congestion control, flow control, and lossless delivery |
| ğŸ”Œ **Hardware offloads** | Handles RDMA operations in the NIC without CPU |
| ğŸ§  **Direct GPU access** | Supports GPUDirect RDMA between GPUs across nodes |
| âš™ï¸ **Optimized protocol stack** | InfiniBand avoids TCP/IP overhead present in RoCE or iWARP |

---

## ğŸ§ª Benchmark Comparison

| Metric | **InfiniBand (IB)** | **RoCEv2 (RDMA over Ethernet)** |
|--------|---------------------|----------------------------------|
| Latency | 1â€“2 microseconds | 5â€“20 microseconds |
| Bandwidth | 200â€“400 Gbps (HDR/NDR) | 100â€“200 Gbps |
| CPU usage | Very low | Higher (due to Ethernet stack) |
| Reliability | Very high | Can vary (depends on network tuning) |

---

## ğŸ¯ TL;DR

- **RDMA** is the method.
- **InfiniBand** is a transport and hardware technology that **implements RDMA extremely efficiently**.
- InfiniBand is **often the fastest RDMA transport**, better than Ethernet-based options.

